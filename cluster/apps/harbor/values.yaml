harbor:
  expose:
    # Set how to expose the service. Set the type as "ingress", "clusterIP", "nodePort" or "loadBalancer"
    # and fill the information in the corresponding section
    type: ingress
    tls:
      # Enable TLS or not.
      # Delete the "ssl-redirect" annotations in "expose.ingress.annotations" when TLS is disabled and "expose.type" is "ingress"
      # Note: if the "expose.type" is "ingress" and TLS is disabled,
      # the port must be included in the command when pulling/pushing images.
      # Refer to https://github.com/goharbor/harbor/issues/5291 for details.
      enabled: true
      # The source of the tls certificate. Set as "auto", "secret"
      # or "none" and fill the information in the corresponding section
      # 1) auto: generate the tls certificate automatically
      # 2) secret: read the tls certificate from the specified secret.
      # The tls certificate can be generated manually or by cert manager
      # 3) none: configure no tls certificate for the ingress. If the default
      # tls certificate is configured in the ingress controller, choose this option
      certSource: auto
      auto:
        # The common name used to generate the certificate, it's necessary
        # when the type isn't "ingress"
        commonName: ""
      secret:
        # The name of secret which contains keys named:
        # "tls.crt" - the certificate
        # "tls.key" - the private key
        secretName: ""
        # The name of secret which contains keys named:
        # "tls.crt" - the certificate
        # "tls.key" - the private key
        # Only needed when the "expose.type" is "ingress".
        notarySecretName: ""
    ingress:
      hosts:
        core: core.harbor.domain
        notary: notary.harbor.domain
      # set to the type of ingress controller if it has specific requirements.
      # leave as `default` for most ingress controllers.
      # set to `gce` if using the GCE ingress controller
      # set to `ncp` if using the NCP (NSX-T Container Plugin) ingress controller
      # set to `alb` if using the ALB ingress controller
      controller: default
      ## Allow .Capabilities.KubeVersion.Version to be overridden while creating ingress
      kubeVersionOverride: ""
      className: ""
      annotations:
        # note different ingress controllers may require a different ssl-redirect annotation
        # for Envoy, use ingress.kubernetes.io/force-ssl-redirect: "true" and remove the nginx lines below
        ingress.kubernetes.io/ssl-redirect: "true"
        ingress.kubernetes.io/proxy-body-size: "0"
        nginx.ingress.kubernetes.io/ssl-redirect: "true"
        nginx.ingress.kubernetes.io/proxy-body-size: "0"
      notary:
        # notary ingress-specific annotations
        annotations: {}
        # notary ingress-specific labels
        labels: {}
      harbor:
        # harbor ingress-specific annotations
        annotations: {}
        # harbor ingress-specific labels
        labels: {}
    

  # The external URL for Harbor core service. It is used to
  # 1) populate the docker/helm commands showed on portal
  # 2) populate the token service URL returned to docker/notary client
  #
  # Format: protocol://domain[:port]. Usually:
  # 1) if "expose.type" is "ingress", the "domain" should be
  # the value of "expose.ingress.hosts.core"
  # 2) if "expose.type" is "clusterIP", the "domain" should be
  # the value of "expose.clusterIP.name"
  # 3) if "expose.type" is "nodePort", the "domain" should be
  # the IP address of k8s node
  #
  # If Harbor is deployed behind the proxy, set it as the URL of proxy
  externalURL: https://core.harbor.domain

  
  # The persistence is enabled by default and a default StorageClass
  # is needed in the k8s cluster to provision volumes dynamically.
  # Specify another StorageClass in the "storageClass" or set "existingClaim"
  # if you already have existing persistent volumes to use
  #
  # For storing images and charts, you can also use "azure", "gcs", "s3",
  # "swift" or "oss". Set it in the "imageChartStorage" section
  persistence:
    enabled: true
    # Setting it to "keep" to avoid removing PVCs during a helm delete
    # operation. Leaving it empty will delete PVCs after the chart deleted
    # (this does not apply for PVCs that are created for internal database
    # and redis components, i.e. they are never deleted automatically)
    resourcePolicy: "keep"
    persistentVolumeClaim:
      registry:
        # Use the existing PVC which must be created manually before bound,
        # and specify the "subPath" if the PVC is shared with other components
        existingClaim: ""
        # Specify the "storageClass" used to provision the volume. Or the default
        # StorageClass will be used (the default).
        # Set it to "-" to disable dynamic provisioning
        storageClass: ""
        subPath: ""
        accessMode: ReadWriteOnce
        size: 5Gi
        annotations: {}
      chartmuseum:
        existingClaim: ""
        storageClass: ""
        subPath: ""
        accessMode: ReadWriteOnce
        size: 5Gi
        annotations: {}
      jobservice:
        jobLog:
          existingClaim: ""
          storageClass: ""
          subPath: ""
          accessMode: ReadWriteOnce
          size: 1Gi
          annotations: {}
        scanDataExports:
          existingClaim: ""
          storageClass: ""
          subPath: ""
          accessMode: ReadWriteOnce
          size: 1Gi
          annotations: {}
      # If external database is used, the following settings for database will
      # be ignored
      database:
        existingClaim: ""
        storageClass: ""
        subPath: ""
        accessMode: ReadWriteOnce
        size: 1Gi
        annotations: {}
      # If external Redis is used, the following settings for Redis will
      # be ignored
      redis:
        existingClaim: ""
        storageClass: ""
        subPath: ""
        accessMode: ReadWriteOnce
        size: 1Gi
        annotations: {}
      trivy:
        existingClaim: ""
        storageClass: ""
        subPath: ""
        accessMode: ReadWriteOnce
        size: 5Gi
        annotations: {}
    # Define which storage backend is used for registry and chartmuseum to store
    # images and charts. Refer to
    # https://github.com/docker/distribution/blob/master/docs/configuration.md#storage
    # for the detail.
    imageChartStorage:
      # Specify whether to disable `redirect` for images and chart storage, for
      # backends which not supported it (such as using minio for `s3` storage type), please disable
      # it. To disable redirects, simply set `disableredirect` to `true` instead.
      # Refer to
      # https://github.com/docker/distribution/blob/master/docs/configuration.md#redirect
      # for the detail.
      disableredirect: false
      # Specify the "caBundleSecretName" if the storage service uses a self-signed certificate.
      # The secret must contain keys named "ca.crt" which will be injected into the trust store
      # of registry's and chartmuseum's containers.
      # caBundleSecretName:

      # Specify the type of storage: "filesystem", "azure", "gcs", "s3", "swift",
      # "oss" and fill the information needed in the corresponding section. The type
      # must be "filesystem" if you want to use persistent volumes for registry
      # and chartmuseum
      type: filesystem
      filesystem:
        rootdirectory: /storage
        #maxthreads: 100
      
  imagePullPolicy: IfNotPresent

  # Use this set to assign a list of default pullSecrets
  imagePullSecrets:
  #  - name: docker-registry-secret
  #  - name: internal-registry-secret

  # The update strategy for deployments with persistent volumes(jobservice, registry
  # and chartmuseum): "RollingUpdate" or "Recreate"
  # Set it as "Recreate" when "RWM" for volumes isn't supported
  updateStrategy:
    type: RollingUpdate

  # debug, info, warning, error or fatal
  logLevel: info

  # The initial password of Harbor admin. Change it from portal after launching Harbor
  harborAdminPassword: "Harbor12345"

  # The name of the secret which contains key named "ca.crt". Setting this enables the
  # download link on portal to download the CA certificate when the certificate isn't
  # generated automatically
  caSecretName: ""

  # The secret key used for encryption. Must be a string of 16 chars.
  secretKey: "not-a-secure-key"
  # If using existingSecretSecretKey, the key must be sercretKey
  existingSecretSecretKey: ""

  # The proxy settings for updating trivy vulnerabilities from the Internet and replicating
  # artifacts from/to the registries that cannot be reached directly
  proxy:
    httpProxy:
    httpsProxy:
    noProxy: 127.0.0.1,localhost,.local,.internal
    components:
      - core
      - jobservice
      - trivy

  # Run the migration job via helm hook
  enableMigrateHelmHook: false

  # The custom ca bundle secret, the secret must contain key named "ca.crt"
  # which will be injected into the trust store for chartmuseum, core, jobservice, registry, trivy components
  # caBundleSecretName: ""

  ## UAA Authentication Options
  # If you're using UAA for authentication behind a self-signed
  # certificate you will need to provide the CA Cert.
  # Set uaaSecretName below to provide a pre-created secret that
  # contains a base64 encoded CA Certificate named `ca.crt`.
  # uaaSecretName:

  metrics:
    enabled: true
    core:
      path: /metrics
      port: 8001
    registry:
      path: /metrics
      port: 8001
    jobservice:
      path: /metrics
      port: 8001
    exporter:
      path: /metrics
      port: 8001
    ## Create prometheus serviceMonitor to scrape harbor metrics.
    ## This requires the monitoring.coreos.com/v1 CRD. Please see
    ## https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/user-guides/getting-started.md
    ##
    serviceMonitor:
      enabled: true
      additionalLabels: {}
      # Scrape interval. If not set, the Prometheus default scrape interval is used.
      interval: ""
      # Metric relabel configs to apply to samples before ingestion.
      metricRelabelings:
        []
        # - action: keep
        #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'
        #   sourceLabels: [__name__]
      # Relabel configs to apply to samples before ingestion.
      relabelings:
        []
        # - sourceLabels: [__meta_kubernetes_pod_node_name]
        #   separator: ;
        #   regex: ^(.*)$
        #   targetLabel: nodename
        #   replacement: $1
        #   action: replace